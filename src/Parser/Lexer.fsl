{

// Opens methods related to fslex.exe
open FSharp.Text.Lexing

let newline (lexbuf: LexBuffer<_>) = 
  lexbuf.EndPos <- lexbuf.StartPos.NextLine
let lexeme = LexBuffer<_>.LexemeString
open Parser.Parser
open Parser.LexHelper
let keywords =
    [
        "_", UNDER_BAR;
        "\\", LAMBDA;
        "lambda", LAMBDA;
        "open", OPEN;
        "import", IMPORT;
        "module", MODULE;
        "public", PUBLIC;
        "refl_", REFL;
    ] |> Map.ofList
}
// Regular expressions
let whitespace = [' ']
let newline = ('\n' | '\r' | "\r\n")
let identChar = [^'\n' '\r' '\n' ' ' '\t' '.' '(' ')' '=' ':' ',' '⇒' '→' 'λ' '.' '{' '}' ';']
let identHead = [^'\n' '\r' '\n' ' ' '\t' '.' '(' ')' '=' ':' ',' '⇒' '→' 'λ' '.' '{' '}' ';']
let identTail = [^'\n' '\r' '\n' ' ' '\t' '.' '(' ')' '=' ':' ',' '⇒' '→' 'λ' '.' '{' '}' ';']
let ident = identHead | (identHead identChar* identTail)
let indent = whiltespace whitespace
let never = 'a'+'a'
let anyZero = never?
rule start (state : LexState) = parse
  | anyZero {
      match state.tokens with
      | [] -> 
        if state.eof then
          failwith "eof"
        else
          tokenstream state lexbuf
      | x::xs ->
        x, {state with tokens = xs}
    }
and tokenstream state = parse
  // --------------------------
  | "." {Lex.token Parser.DOT state}
  // --------------------------
  | "(" {Lex.token LPAREN state}
  | ")" {Lex.token RPAREN state}
  | "=" {Lex.token EQ state}
  | ":" {Lex.token COLON state}
  | ";" {Lex.token SEMICOLON state}
  | "," {Lex.token COMMA state}
  | "→" {Lex.token ARROW state}
  | "⇒" {Lex.token DARROW state}
  | "=>" {Lex.token DARROW state}
  | "->" {Lex.token ARROW state}
  | "λ" {Lex.token LAMBDA state}
  | "." {Lex.token DOT state}
  | "*" {Lex.token STAR state}
  | "∗" {Lex.token STAR state}
  | "□" {Lex.token RECT state}
  | "{" {Lex.token BLOCKBEGIN state}
  | "}" {Lex.token BLOCKEND state}
  | "where" {
    start {
      state with
        acceptIndent = true
        tokens = [WHERE]
    } lexbuf}
  | whitespace	{
    start state lexbuf} 
  | newline	whitespace* { 
    newline lexbuf
    let depth = (lexeme lexbuf).Length - 1
    let rec loop i indents =
      match indents with
      | [] -> i, []
      | x::xs -> 
        if depth < x then
          loop (i+1) xs
        else
          i, indents
    if state.acceptIndent then
      let state = {
        state with
          acceptIndent = false
      }
      match state.indents with
      | x::xs ->
        if depth > x then
          start 
            {state with
              indents = depth::state.indents
              tokens = [BLOCKBEGIN]
            } 
            lexbuf
        else
          let (i, ls) = loop 1 xs
          start 
            {
              state with  
                indents = ls
                tokens = List.replicate i BLOCKEND
            } 
            lexbuf 
      | [] ->
        start 
          {state with
            indents = [depth]
            tokens = [BLOCKBEGIN]
          } 
          lexbuf
    else
      let (i, ls) = loop 0 state.indents
      start 
        {state with
          indents = ls
          tokens = 
            [
              SEMICOLON
              for _ in 1..i do
                BLOCKEND
            ]
        } 
        lexbuf }
  | ident {
    match keywords.TryFind(lexeme lexbuf) with
                  | Some(token) -> Lex.token token state
                  | None -> Lex.token (IDENT(lexeme lexbuf)) state
  }
  // --------------------------
  | _    		{ 
      failwith ("ParseError" + LexBuffer<_>.LexemeString lexbuf) }
  | eof   	{ 
    start
      {
        state with
          eof = true
          tokens = [
            for _ in state.indents do
              BLOCKEND
            EOF
          ]}
      lexbuf
  }